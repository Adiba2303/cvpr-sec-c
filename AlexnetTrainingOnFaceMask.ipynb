import os
import cv2
import joblib
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping
joblib_in = open("D:/Documents/CVPR/Resources/face_mask/X_train.joblib","rb")
X_train = joblib.load(joblib_in)

joblib_in = open("D:/Documents/CVPR/Resources/face_mask/Y_train.joblib","rb")
Y_train = joblib.load(joblib_in)

joblib_in = open("D:/Documents/CVPR/Resources/face_mask/X_valid.joblib","rb")
X_valid = joblib.load(joblib_in)

joblib_in = open("D:/Documents/CVPR/Resources/face_mask/Y_valid.joblib","rb")
Y_valid = joblib.load(joblib_in)

joblib_in = open("D:/Documents/CVPR/Resources/face_mask/X_test.joblib","rb")
X_test = joblib.load(joblib_in)

joblib_in = open("D:/Documents/CVPR/Resources/face_mask/Y_test.joblib","rb")
Y_test = joblib.load(joblib_in)

print(f"X_train= {X_train.shape} Y_train= {Y_train.shape}")
print(f"X_valid= {X_valid.shape} Y_valid= {Y_valid.shape}")
print(f"X_test= {X_test.shape} Y_test= {Y_test.shape}")
mean_img = np.mean(X_train, axis=0)
plt.imshow(mean_img.astype('uint8'))

X_train_norm, X_valid_norm, X_test_norm = X_train-mean_img, X_valid-mean_img, X_test-mean_img
c = 0
plt.figure(figsize=(5,10))
for i in range(10):
    plt.subplot(10,2,c+1)
    plt.imshow(X_train[i].astype('uint8'))
    plt.xticks([])
    plt.yticks([])
    
    plt.subplot(10,2,c+2)
    plt.imshow(X_train_norm[i].astype('uint8'))
    plt.xticks([])
    plt.yticks([])

    c += 2
    
plt.tight_layout()
plt.show()

model = keras.Sequential([
    ## input layer
    keras.Input(shape=(64,64,3)),
    
    
    layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='same'),
    layers.Activation('relu'),
    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),
    layers.BatchNormalization(),
    
    layers.Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='same'),
    layers.Activation('relu'),
    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),
    layers.BatchNormalization(),
    
    layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'),
    layers.Activation('relu'),
    layers.BatchNormalization(),
    
    layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'),
    layers.Activation('relu'),
    layers.BatchNormalization(),
    
    layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'),
    layers.Activation('relu'),
    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'),
    layers.BatchNormalization(),
    
    layers.Flatten(),
    
    layers.Dense(units=4096),
    layers.Activation('relu'),
    layers.Dropout(0.5),
    layers.BatchNormalization(),
    
    layers.Dense(units=4096),
    layers.Activation('relu'),
    layers.Dropout(0.5),
    layers.BatchNormalization(),

    layers.Dense(2),
    layers.Activation('softmax')
])

model.summary()
model.compile(
    optimizer='adam', 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)
cb = EarlyStopping(monitor='val_loss', min_delta = 0.02, patience=3, restore_best_weights= True)
h = model.fit(x=X_train_norm, y=Y_train, epochs=20, validation_data=(X_valid_norm, Y_valid), batch_size=32, callbacks=[cb])
plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(h.history['accuracy'], 'o-', label='train accuracy')
plt.plot(h.history['val_accuracy'], 'o-', label = 'validation accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.grid(True)
plt.legend(loc='lower right')

plt.subplot(1,2,2)
plt.plot(h.history['loss'], 'o-', label='train loss')
plt.plot(h.history['val_loss'], 'o-', label='validation loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)
plt.legend(loc='upper right')

plt.show()

model.save('D:/Documents/CVPR/Resources/face_mask/Models/AlexNetOnFaceMask.h5')

